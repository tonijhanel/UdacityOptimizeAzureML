# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**Objective:** 

To predict whether a bank client will subscribe to a term deposit ("yes" or "no").

The goal of this project is to develop a predictive model that can accurately determine if a bank client will subscribe to a term deposit. Using the Bankmarketing [dataset](https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv), which includes customer demographics such as age, job, and education, as well as details about the marketing campaign, this is a binary classification problem. 

The aim is to classify clients as either "yes" or "no" based on their likelihood to subscribe. To achieve the best possible model performance, the Azure Machine Learning platform will be utilized, specifically leveraging AutoML and HyperDrive optimization techniques. These tools will help in exploring various models and hyperparameters to identify the most effective solution for this prediction task.



**Findings:**

Employing Azure Machine Learning, both AutoML and HyperDrive optimization were utilized. AutoML yielded a Voting Ensemble model with the highest accuracy of 0.91903. In contrast, HyperDrive, when configured with a Logistic Regression algorithm, achieved a peak accuracy of 0.90932, specifically with a maximum iteration setting of 100 and a regularization strength of 0.0220308670. Therefore, AutoML's Voting Ensemble model slightly outperformed the HyperDrive-optimized Logistic Regression in terms of accuracy.

* **AutoML**: Achieved highest accuracy with a Voting Ensemble model.
    * Accuracy: 0.91903.

* **HyperDrive (Logistic Regression)**: Optimized model parameters.
    * Parameters: max_itter = 100, Regularization Strength = 0.0220308670.
    * Accuracy: 0.90932.



## Scikit-learn Pipeline
* **Data:** The pipeline utilized the Bankmarketing dataset, which includes customer demographics (age, job, education) and campaign details.

* **Hyperparameter Tuning:**
    * Azure ML's HyperDrive was used to optimize the hyperparameters of a Logistic Regression algorithm.

    * Tuned hyperparameters:
        * C (Regularization Strength)
        * max_iter (Maximum Iterations)

    * **RandomParameterSampling** was employed to explore the hyperparameter space.
* **Classification Algorithm:** Logistic Regression was the chosen classification algorithm.

**Benefits of RandomParameterSampling:**

* **Exploration of Hyperparameter Space:** Allows for a broad, unbiased exploration, especially when optimal values are unknown.
* **Simplicity:** Easy to implement, requires no prior knowledge of hyperparameter relationships.
* **Efficiency:** More efficient than grid search in high-dimensional spaces.

**Benefits of BanditPolicy for Early Stopping:**

* **Resource Efficiency:** Stops poorly performing runs early, saving computational resources and time.
* **Faster Optimization:** Accelerates convergence by focusing on promising runs.
* **Improved Performance:** Allocates more resources to better-performing runs, potentially leading to a better final model.

## AutoML
**AutoML Model Summary:**

The optimal model generated by Azure AutoML was a Voting Ensemble, which strategically combined several high-performing classification algorithms. Specifically, it included LightGBM, XGBoostClassifier, and RandomForestClassifier, leveraging the strengths of each to improve overall predictive accuracy. To enhance the data's suitability for these algorithms, AutoML applied various data transformation techniques, such as MaxAbsScaler, StandardScalerWrapper, and SparseNormalizer.

**Hyperparameter and Configuration Details:**

* **Ensemble Composition:** The ensemble was constructed from a combination of XGBoostClassifier, LightGBM, and RandomForest models.
* **Ensemble Weights:** The individual models within the ensemble were weighted to optimize performance, with XGBoostClassifier receiving a significant weight of approximately 0.428.
* **Data Transformation:** MaxAbsScaler, StandardScalerWrapper, and SparseNormalizer were used to preprocess the data, ensuring optimal input for the chosen algorithms.
* **Optimization Metric:** The model was optimized for accuracy, achieving a best individual pipeline score of approximately 0.916.
* **Experiment Settings:** The AutoML experiment was configured with a 30-minute time limit, enabled early stopping to conserve resources, and utilized a maximum of 4 concurrent iterations. Certain models, like KNN and LinearSVM, were blocked, and ONNX-compatible models were enabled.*

## Pipeline comparison
**Accuracy:**

* **AutoML:** Achieved a higher accuracy of 0.91903 with its Voting Ensemble model.

* **HyperDrive:** Reached an accuracy of 0.90932 using a Logistic Regression algorithm with optimized hyperparameters.

**Architecture:**

* **AutoML:** The best model was a Voting Ensemble, combining LightGBM, XGBoostClassifier, and RandomForestClassifier, along with data transformations like MaxAbsScaler and StandardScalerWrapper.

* **HyperDrive:** The model was a Logistic Regression algorithm, with hyperparameters tuned using RandomParameterSampling.

**Why the Difference?**

The difference in performance likely stems from the architectural differences. AutoML's Voting Ensemble leverages the strengths of multiple algorithms, creating a more robust and potentially more accurate model than a single Logistic Regression model, even with optimized hyperparameters. Ensemble methods often outperform individual algorithms because they reduce bias and variance by combining diverse perspectives.

## Future work
**Areas of Improvement for Future Experiments:**

**1. Expanded Hyperparameter Tuning:**

* **Improvement:** For both AutoML and HyperDrive, explore a wider range of hyperparameters and algorithms.
* **Why:**
    * AutoML might find even better ensemble combinations or data transformations.
    * HyperDrive could benefit from tuning more hyperparameters or trying different algorithms altogether (e.g., Gradient Boosting, Support Vector Machines). A more extensive search might uncover optimal settings that were missed.

**2. Feature Engineering:**

* **Improvement:** Invest more time in feature engineering, creating new features or transforming existing ones.
* **Why:**
    * Feature engineering can often have a greater impact on model performance than hyperparameter tuning.

**3. Addressing Class Imbalance:**

* **Improvement:** **This is a crucial step.** Implement techniques to address the significant class imbalance. This includes:
    * **Oversampling the minority class ("yes"):** Techniques like SMOTE (Synthetic Minority Over-sampling Technique) can generate synthetic samples of the minority class.
    * **Undersampling the majority class ("no"):** Reducing the number of samples in the majority class.
    * **Using class weights:** Adjusting the algorithm's weights to penalize errors in the minority class more heavily.
    * **Using evaluation metrics that are less sensitive to class imbalance:** Focus on metrics like precision, recall, F1-score, and AUC-ROC, rather than just accuracy.
* **Why:**
    * Imbalanced data can lead to models that are heavily biased towards the majority class, resulting in poor performance on the minority class.
    * Addressing class imbalance is essential to improve the model's ability to correctly predict the "yes" class, which is likely the more important class in this context.


**4. Increase experiment time.**

* **Improvement:** Increase the amount of time that the AutoML and Hyperdrive experiments are allowed to run.
* **Why:**
    * Some times the experiment is cut short, due to time constraints, before the best model can be located. Giving the experiment more time, increases the chances of a better model being found.
## Proof of cluster clean up

N/A - Using my own Azure ML Studio subscription
